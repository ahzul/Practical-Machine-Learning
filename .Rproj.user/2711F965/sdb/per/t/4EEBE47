{
    "contents" : "---\ntitle: \"PRACTICAL MACHINE LEARNING COURSE PROJECT\"\nauthor: \"Zulkarnain Abu Hassan\"\ndate: \"January 14, 2016\"\noutput: pdf_document\n---\n\n#1.SYNOPSIS\nThe goal of this project is to predict the manner in which they did the exercise based on the Training Dataset & Testing Dataset given\n\nThe report should describe:\n\n•\t“how you built your model”\n\n•\t“how you used cross validation”\n\n•\t“what you think the expected out of sample error is”\n\n•\t“why you made the choices you did”\n\nUltimately, the prediction model is to be run on the test data to predict the outcome of 20 different test cases.\n\nIn the aforementioned study, six participants participated in a dumbell lifting exercise five different ways. The five ways, as described in the study, were “exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E). Class A corresponds to the specified execution of the exercise, while the other 4 classes correspond to common mistakes.”\n\nBy processing data gathered from accelerometers on the belt, forearm, arm, and dumbell of the participants in a machine learning algorithm, the question is can the appropriate activity quality (class A-E) be predicted?\n\n#2.Loading the appropriate packages\n\n```{r}\nlibrary(caret)\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\nlibrary(randomForest)\nlibrary(rpart)\nlibrary(rpart.plot)\nlibrary(rattle) \nlibrary(RColorBrewer) \n```\n\n#3.Getting and loading the data\n\n```{r}\nset.seed(12345)\n\ntrainUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\ntestUrl <- \"http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\n\ntraining <- read.csv(url(trainUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\ntesting <- read.csv(url(testUrl), na.strings=c(\"NA\",\"#DIV/0!\",\"\"))\n```\n\n#4.Partioning the training set into two\n\nPartioning Training data set into two data sets, 60% for myTraining, 40% for myTesting:\n\n```{r}\ninTrain <- createDataPartition(training$classe, p=0.6, list=FALSE)\nmyTraining <- training[inTrain, ]\nmyTesting <- training[-inTrain, ]\ndim(myTraining); dim(myTesting)\n```\n\n#5.\tCleaning the data\n\na.\tRemove NearZeroVariance variables\n\n```{r}\nnzv <- nearZeroVar(myTraining, saveMetrics=TRUE)\nmyTraining <- myTraining[,nzv$nzv==FALSE]\n\nnzv<- nearZeroVar(myTesting,saveMetrics=TRUE)\nmyTesting <- myTesting[,nzv$nzv==FALSE]\n```\n\n\nb.\tRemove the first column of the myTraining data set\n\n```{r}\nmyTraining <- myTraining[c(-1)]\n```\n\n\nc.\tClean variables with more than 60% NA\n\n```{r}\ntrainingV3 <- myTraining\nfor(i in 1:length(myTraining)) {\n    if( sum( is.na( myTraining[, i] ) ) /nrow(myTraining) >= .7) {\n        for(j in 1:length(trainingV3)) {\n            if( length( grep(names(myTraining[i]), names(trainingV3)[j]) ) == 1)  {\n                trainingV3 <- trainingV3[ , -j]\n            }   \n        } \n    }\n}\n\n```\n\n```{r}\n# Set back to the original variable name\nmyTraining <- trainingV3\nrm(trainingV3)\n\n```\n\n\nd.\tTransform the myTesting and testing data sets\n\n```{r}\nclean1 <- colnames(myTraining)\n# remove the classe column\nclean2 <- colnames(myTraining[, -58])  \n# allow only variables in myTesting that are also in myTraining\nmyTesting <- myTesting[clean1]         \n# allow only variables in testing that are also in myTraining\ntesting <- testing[clean2]             \n\ndim(myTesting)\ndim(testing)\n```\n\n\ne.\tCoerce the data into the same type\n\n```{r}\nfor (i in 1:length(testing) ) {\n    for(j in 1:length(myTraining)) {\n        if( length( grep(names(myTraining[i]), names(testing)[j]) ) == 1)  {\n            class(testing[j]) <- class(myTraining[i])\n        }      \n    }      \n}\n\n# To get the same class between testing and myTraining\ntesting <- rbind(myTraining[2, -58] , testing)\ntesting <- testing[-1,]\n\n```\n\n\n#6.\tPrediction Analysis using\n\na.\tDecision Trees\n\n```{r}\nset.seed(12345)\nmodFitA1 <- rpart(classe ~ ., data=myTraining, method=\"class\")\nfancyRpartPlot(modFitA1)\n\n```\n\n```{r}\npredictionsA1 <- predict(modFitA1, myTesting, type = \"class\")\ncmtree <- confusionMatrix(predictionsA1, myTesting$classe)\ncmtree\n\n```\n\n```{r}\nplot(cmtree$table, col = cmtree$byClass, main = paste(\"Decision Tree Confusion Matrix: Accuracy =\", round(cmtree$overall['Accuracy'], 4)))\n\n```\n\nb.\tRandom Forests\n\n```{r}\nset.seed(12345)\nmodFitB1 <- randomForest(classe ~ ., data=myTraining)\npredictionB1 <- predict(modFitB1, myTesting, type = \"class\")\ncmrf <- confusionMatrix(predictionB1, myTesting$classe)\ncmrf\n\n```\n\n```{r}\nplot(modFitB1)\n\n```\n\n```{r}\nplot(cmrf$table, col = cmtree$byClass, main = paste(\"Random Forest Confusion Matrix: Accuracy =\", round(cmrf$overall['Accuracy'], 4)))\n\n```\n\n\n#7. Predicting Results on the Test Data\n\nRandom Forests gave an Accuracy in the myTesting dataset of 99.89%, which was more accurate that what I got from the Decision Trees. The expected out-of-sample error is 100-99.89 = 0.11%.\n",
    "created" : 1452744807879.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2507388570",
    "id" : "4EEBE47",
    "lastKnownWriteTime" : 1452767104,
    "path" : "D:/SIU2/Big_Data_Course/08-Practical_Machine_Learning/Project/Project/Training1.Rmd",
    "project_path" : "Training1.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "type" : "r_markdown"
}